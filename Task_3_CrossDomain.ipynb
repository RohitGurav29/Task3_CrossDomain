{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import Tk, filedialog, Label, Button, Radiobutton, IntVar\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Colorization Model\n",
    "class ColorizationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=4, dilation=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=4, dilation=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=4, dilation=2)\n",
    "        self.conv4 = nn.Conv2d(128, 3, kernel_size=5, stride=1, padding=4, dilation=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.sigmoid(self.conv4(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB Image to Grayscale\n",
    "def rgb_to_gray(img):\n",
    "    return img.mean(dim=1, keepdim=True)\n",
    "\n",
    "# Convert RGB to Sketch using Canny Edge Detection\n",
    "def rgb_to_sketch(img):\n",
    "    img_np = np.transpose(img.numpy(), (1, 2, 0)) * 255  # Convert tensor to numpy\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    sketch = cv2.Canny(gray, 100, 200)\n",
    "    sketch_tensor = torch.from_numpy(sketch).unsqueeze(0).float() / 255  # Convert back to tensor\n",
    "    return sketch_tensor\n",
    "\n",
    "# Convert RGB to Infrared (Simulated by Converting RGB Channels)\n",
    "def rgb_to_infrared(img):\n",
    "    img_np = np.transpose(img.numpy(), (1, 2, 0)) * 255  # Convert tensor to numpy\n",
    "    infrared = img_np[:, :, 0]  # Use the red channel as a proxy for infrared\n",
    "    infrared_tensor = torch.from_numpy(infrared).unsqueeze(0).float() / 255  # Convert back to tensor\n",
    "    return infrared_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ColorizationNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.0049\n",
      "Epoch [2/30], Loss: 0.0044\n",
      "Epoch [3/30], Loss: 0.0049\n",
      "Epoch [4/30], Loss: 0.0031\n",
      "Epoch [5/30], Loss: 0.0046\n",
      "Epoch [6/30], Loss: 0.0036\n",
      "Epoch [7/30], Loss: 0.0043\n",
      "Epoch [8/30], Loss: 0.0038\n",
      "Epoch [9/30], Loss: 0.0045\n",
      "Epoch [10/30], Loss: 0.0050\n",
      "Epoch [11/30], Loss: 0.0044\n",
      "Epoch [12/30], Loss: 0.0043\n",
      "Epoch [13/30], Loss: 0.0057\n",
      "Epoch [14/30], Loss: 0.0046\n",
      "Epoch [15/30], Loss: 0.0035\n",
      "Epoch [16/30], Loss: 0.0057\n",
      "Epoch [17/30], Loss: 0.0027\n",
      "Epoch [18/30], Loss: 0.0040\n",
      "Epoch [19/30], Loss: 0.0042\n",
      "Epoch [20/30], Loss: 0.0029\n",
      "Epoch [21/30], Loss: 0.0047\n",
      "Epoch [22/30], Loss: 0.0033\n",
      "Epoch [23/30], Loss: 0.0022\n",
      "Epoch [24/30], Loss: 0.0042\n",
      "Epoch [25/30], Loss: 0.0025\n",
      "Epoch [26/30], Loss: 0.0042\n",
      "Epoch [27/30], Loss: 0.0055\n",
      "Epoch [28/30], Loss: 0.0052\n",
      "Epoch [29/30], Loss: 0.0036\n",
      "Epoch [30/30], Loss: 0.0060\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        grayscale_images = rgb_to_gray(images).to(device)\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        outputs = model(grayscale_images)\n",
    "        loss = criterion(outputs, images)\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'colorization_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\1046018220.py\", line 55, in colorize_image\n",
      "    colorized_tensor = model(img_tensor)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\3503885128.py\", line 11, in forward\n",
      "    x = torch.relu(self.conv1(x))\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 458, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 454, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Given groups=1, weight of size [64, 1, 5, 5], expected input[1, 3, 1, 200] to have 1 channels, but got 3 channels instead\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\1046018220.py\", line 38, in upload_image\n",
      "    processed_img = rgb_to_sketch(img_tensor)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\4245260898.py\", line 9, in rgb_to_sketch\n",
      "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
      "cv2.error: OpenCV(4.5.4) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x694991f6::Set<1,-1,-1>,struct cv::impl::A0x694991f6::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n",
      "> Invalid number of channels in input image:\n",
      ">     'VScn::contains(scn)'\n",
      "> where\n",
      ">     'scn' is 1\n",
      "\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\1046018220.py\", line 38, in upload_image\n",
      "    processed_img = rgb_to_sketch(img_tensor)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\4245260898.py\", line 9, in rgb_to_sketch\n",
      "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
      "cv2.error: OpenCV(4.5.4) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x694991f6::Set<1,-1,-1>,struct cv::impl::A0x694991f6::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n",
      "> Invalid number of channels in input image:\n",
      ">     'VScn::contains(scn)'\n",
      "> where\n",
      ">     'scn' is 1\n",
      "\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py\", line 2979, in open\n",
      "    fp.seek(0)\n",
      "AttributeError: 'str' object has no attribute 'seek'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\1046018220.py\", line 29, in upload_image\n",
      "    img = Image.open(file_path)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py\", line 2981, in open\n",
      "    fp = io.BytesIO(fp.read())\n",
      "AttributeError: 'str' object has no attribute 'read'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py\", line 2979, in open\n",
      "    fp.seek(0)\n",
      "AttributeError: 'str' object has no attribute 'seek'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\1046018220.py\", line 29, in upload_image\n",
      "    img = Image.open(file_path)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py\", line 2981, in open\n",
      "    fp = io.BytesIO(fp.read())\n",
      "AttributeError: 'str' object has no attribute 'read'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py\", line 2979, in open\n",
      "    fp.seek(0)\n",
      "AttributeError: 'str' object has no attribute 'seek'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\1046018220.py\", line 29, in upload_image\n",
      "    img = Image.open(file_path)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py\", line 2981, in open\n",
      "    fp = io.BytesIO(fp.read())\n",
      "AttributeError: 'str' object has no attribute 'read'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py\", line 2979, in open\n",
      "    fp.seek(0)\n",
      "AttributeError: 'str' object has no attribute 'seek'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Local\\Temp\\ipykernel_14724\\1046018220.py\", line 29, in upload_image\n",
      "    img = Image.open(file_path)\n",
      "  File \"C:\\Users\\Rohit\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\Image.py\", line 2981, in open\n",
      "    fp = io.BytesIO(fp.read())\n",
      "AttributeError: 'str' object has no attribute 'read'\n"
     ]
    }
   ],
   "source": [
    "class ImageColorizer:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Cross-Domain Image Colorization\")\n",
    "        self.root.geometry(\"800x500\")\n",
    "\n",
    "        # Buttons and Labels\n",
    "        self.label = Label(root, text=\"Upload an Image\")\n",
    "        self.label.pack()\n",
    "\n",
    "        self.domain = IntVar()\n",
    "        Radiobutton(root, text=\"RGB\", variable=self.domain, value=1).pack(anchor=\"w\")\n",
    "        Radiobutton(root, text=\"Sketch\", variable=self.domain, value=2).pack(anchor=\"w\")\n",
    "        Radiobutton(root, text=\"Infrared\", variable=self.domain, value=3).pack(anchor=\"w\")\n",
    "\n",
    "        self.upload_button = Button(root, text=\"Upload Image\", command=self.upload_image)\n",
    "        self.upload_button.pack()\n",
    "        self.colorize_button = Button(root, text=\"Colorize Image\", command=self.colorize_image)\n",
    "        self.colorize_button.pack()\n",
    "        self.reset_button = Button(root, text=\"Reset\", command=self.reset_image)\n",
    "        self.reset_button.pack()\n",
    "\n",
    "        self.original_image = None\n",
    "        self.processed_image = None\n",
    "        self.colorized_image = None\n",
    "\n",
    "    def upload_image(self):\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        img = Image.open(file_path)\n",
    "        self.original_image = img\n",
    "\n",
    "        # Convert to Grayscale/Sketch/Infrared based on selection\n",
    "        domain_choice = self.domain.get()\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        if domain_choice == 1:\n",
    "            processed_img = rgb_to_gray(img_tensor)\n",
    "        elif domain_choice == 2:\n",
    "            processed_img = rgb_to_sketch(img_tensor)\n",
    "        else:\n",
    "            processed_img = rgb_to_infrared(img_tensor)\n",
    "\n",
    "        self.processed_image = transforms.ToPILImage()(processed_img)\n",
    "\n",
    "        # Display Original and Processed Images\n",
    "        self.display_images(self.original_image, self.processed_image)\n",
    "\n",
    "    def colorize_image(self):\n",
    "        if self.processed_image:\n",
    "            # Transform Processed Image to Tensor\n",
    "            img_tensor = transforms.ToTensor()(self.processed_image).unsqueeze(0).to(device)\n",
    "\n",
    "            # Model Prediction\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                colorized_tensor = model(img_tensor)\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            self.colorized_image = transforms.ToPILImage()(colorized_tensor.squeeze(0).cpu())\n",
    "\n",
    "            # Display Colorized Image\n",
    "            self.display_images(self.original_image, self.colorized_image)\n",
    "\n",
    "    def display_images(self, original, processed):\n",
    "        original.thumbnail((200, 200))\n",
    "        processed.thumbnail((200, 200))\n",
    "\n",
    "        # Display Original Image\n",
    "        original_photo = ImageTk.PhotoImage(original)\n",
    "        original_label = Label(self.root, image=original_photo)\n",
    "        original_label.image = original_photo\n",
    "        original_label.pack(side=\"left\")\n",
    "\n",
    "        # Display Processed Image\n",
    "        processed_photo = ImageTk.PhotoImage(processed)\n",
    "        processed_label = Label(self.root, image=processed_photo)\n",
    "        processed_label.image = processed_photo\n",
    "        processed_label.pack(side=\"right\")\n",
    "\n",
    "    def reset_image(self):\n",
    "        for widget in self.root.pack_slaves():\n",
    "            widget.destroy()\n",
    "        self.__init__(self.root)\n",
    "\n",
    "# Running the GUI\n",
    "if __name__ == \"__main__\":\n",
    "    root = Tk()\n",
    "    app = ImageColorizer(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "So, above code executed successfully. And the output images can been seen in report and as well as folder named images .\n",
    "Thank you\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
